version: '3.9'

services:
  snapshotter-lite-local-collector:
    image: snapshotter-lite-local-collector
    profiles: ["local-collector"]
    expose:
      - ${LOCAL_COLLECTOR_PORT}
    ports:
      - ${LOCAL_COLLECTOR_PORT}:${LOCAL_COLLECTOR_PORT}
    volumes:
      - ./shared-volume:/keys
    environment:
      - SIGNER_ACCOUNT_ADDRESS=$SIGNER_ACCOUNT_ADDRESS
      - SIGNER_ACCOUNT_PRIVATE_KEY=$SIGNER_ACCOUNT_PRIVATE_KEY
      - IPFS_URL=$IPFS_URL
      - IPFS_API_KEY=$IPFS_API_KEY
      - IPFS_API_SECRET=$IPFS_API_SECRET
      - PROTOCOL_STATE_CONTRACT=$PROTOCOL_STATE_CONTRACT
      - PROST_RPC_URL=$PROST_RPC_URL
      - PROST_CHAIN_ID=$PROST_CHAIN_ID
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - LOCAL_COLLECTOR_PORT=$LOCAL_COLLECTOR_PORT
      - RELAYER_PRIVATE_KEY=$RELAYER_PRIVATE_KEY
      - BLOCK_TIME=$BLOCK_TIME
      - DATA_MARKET_CONTRACT=$DATA_MARKET_CONTRACT
      - MAX_STREAM_POOL_SIZE=$MAX_STREAM_POOL_SIZE
      - STREAM_HEALTH_CHECK_TIMEOUT_MS=$STREAM_HEALTH_CHECK_TIMEOUT_MS
      - STREAM_WRITE_TIMEOUT_MS=$STREAM_WRITE_TIMEOUT_MS
      - MAX_WRITE_RETRIES=$MAX_WRITE_RETRIES
      - MAX_CONCURRENT_WRITES=$MAX_CONCURRENT_WRITES
      - DATA_MARKET_IN_REQUEST=$DATA_MARKET_IN_REQUEST
    networks:
      - custom_network
    restart: on-failure:10
  snapshotter-lite-v2:
    image: snapshotter-lite-v2
    expose:
      - ${CORE_API_PORT}
    ports:
      - ${CORE_API_PORT}:${CORE_API_PORT}
    volumes:
      - ./logs-${NAMESPACE}:/logs
      - ./computes-${NAMESPACE}:/computes
      - ./config-${NAMESPACE}:/config
    environment:
      - SIGNER_ACCOUNT_ADDRESS=$SIGNER_ACCOUNT_ADDRESS
      - SIGNER_ACCOUNT_PRIVATE_KEY=$SIGNER_ACCOUNT_PRIVATE_KEY
      - SLOT_ID=$SLOT_ID
      - SOURCE_RPC_URL=$SOURCE_RPC_URL
      - PROST_RPC_URL=$PROST_RPC_URL
      - IPFS_URL=$IPFS_URL
      - DATA_MARKET_CONTRACT=$DATA_MARKET_CONTRACT
      - IPFS_API_KEY=$IPFS_API_KEY
      - IPFS_API_SECRET=$IPFS_API_SECRET
      - PROTOCOL_STATE_CONTRACT=$PROTOCOL_STATE_CONTRACT
      - SLACK_REPORTING_URL=$SLACK_REPORTING_URL
      - LOCAL_COLLECTOR_PORT=$LOCAL_COLLECTOR_PORT
      - POWERLOOM_REPORTING_URL=$POWERLOOM_REPORTING_URL
      - WEB3_STORAGE_TOKEN=$WEB3_STORAGE_TOKEN
      - NAMESPACE=$NAMESPACE
      - TELEGRAM_REPORTING_URL=$TELEGRAM_REPORTING_URL
      - TELEGRAM_CHAT_ID=$TELEGRAM_CHAT_ID
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    command:
      bash -c "bash snapshotter_autofill.sh && bash init_docker.sh"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - custom_network
  ipfs:
    image: ipfs/kubo:release
    profiles: ["ipfs"]
    environment:
      - IPFS_PROFILE=server
      - DATA_CLEANUP_DAYS=3
      - CLEANUP_SCHEDULE=0 * * * *
    entrypoint: >
      /bin/sh -c '
      echo "Setting up data cleanup cron job...";
      mkdir -p /var/spool/cron/crontabs;
      cleanup_cmd="date && echo \"Starting hourly cleanup process...\" && find /data/ipfs -type f -mtime +$${DATA_CLEANUP_DAYS} -name \"*.data\" -print -delete && echo \"Cron cleanup process completed.\"";
      echo "$${CLEANUP_SCHEDULE} $${cleanup_cmd} >> /proc/1/fd/1 2>&1" > /var/spool/cron/crontabs/root;
      chmod 0644 /var/spool/cron/crontabs/root;

      echo "Cron job set up. Will clean files older than $${DATA_CLEANUP_DAYS} days every hour ($${CLEANUP_SCHEDULE})";

      echo "Starting cron daemon...";
      crond;

      echo "Starting IPFS daemon...";
      exec /sbin/tini -- /usr/local/bin/start_ipfs daemon --migrate=true --agent-version-suffix=docker
      '
    volumes:
      - ipfs_data:/data/ipfs
    ports:
      - "4001:4001"  # Swarm listening port
      - "5001:5001"  # API server
      # - "8080:8080"  # Gateway
    healthcheck:
      test: ["CMD", "ipfs", "id"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - custom_network
networks:
  custom_network:
    name: ${DOCKER_NETWORK_NAME}
    driver: bridge
    ipam:
      config:
        - subnet: ${DOCKER_NETWORK_SUBNET}
volumes:
  ipfs_data:
    name: ipfs_data
